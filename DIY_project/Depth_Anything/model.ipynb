{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-26T06:44:19.292309Z",
     "start_time": "2025-03-26T06:44:19.273342Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResidualConvUnit(nn.Module):\n",
    "    \"\"\"Residual Convolutional Unit\"\"\"\n",
    "    def __init__(self, features, activation, bn):\n",
    "        super().__init__()\n",
    "        self.bn = bn\n",
    "        self.conv1 = nn.Conv2d(features, features, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.conv2 = nn.Conv2d(features, features, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        if self.bn:\n",
    "            self.bn1 = nn.BatchNorm2d(features)\n",
    "            self.bn2 = nn.BatchNorm2d(features)\n",
    "        self.activation = activation\n",
    "        self.skip_add = nn.quantized.FloatFunctional()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.activation(x)\n",
    "        out = self.conv1(out)\n",
    "        if self.bn:\n",
    "            out = self.bn1(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.conv2(out)\n",
    "        if self.bn:\n",
    "            out = self.bn2(out)\n",
    "        return self.skip_add.add(out, x)\n",
    "\n",
    "class FeatureFusionBlock(nn.Module):\n",
    "    \"\"\"Feature Fusion Block\"\"\"\n",
    "    def __init__(self, features, activation, deconv=False, bn=False, expand=False, align_corners=True, size=None):\n",
    "        super().__init__()\n",
    "        self.deconv = deconv\n",
    "        self.align_corners = align_corners\n",
    "        self.expand = expand\n",
    "        out_features = features if not expand else features // 2\n",
    "        self.out_conv = nn.Conv2d(features, out_features, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        self.rcu1 = ResidualConvUnit(features, activation, bn)\n",
    "        self.rcu2 = ResidualConvUnit(features, activation, bn)\n",
    "        self.skip_add = nn.quantized.FloatFunctional()\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, *xs, size=None):\n",
    "        output = xs[0]\n",
    "        if len(xs) == 2:\n",
    "            output = self.skip_add.add(output, self.rcu1(xs[1]))\n",
    "        output = self.rcu2(output)\n",
    "        modifier = {\"scale_factor\": 2} if (size is None and self.size is None) else {\"size\": size or self.size}\n",
    "        output = F.interpolate(output, **modifier, mode=\"bilinear\", align_corners=self.align_corners)\n",
    "        output = self.out_conv(output)\n",
    "        return output\n",
    "\n",
    "def _make_fusion_block(features, use_bn, size=None):\n",
    "    return FeatureFusionBlock(features, nn.ReLU(False), deconv=False, bn=use_bn, expand=False, align_corners=True, size=size)\n",
    "\n",
    "def _make_scratch(in_shape, out_shape, groups=1, expand=False):\n",
    "    scratch = nn.Module()\n",
    "    # 각 레벨별 output 채널 (단순 구조 그대로)\n",
    "    out_shape1, out_shape2, out_shape3 = out_shape, out_shape, out_shape\n",
    "    if len(in_shape) >= 4:\n",
    "        out_shape4 = out_shape\n",
    "    if expand:\n",
    "        out_shape1 = out_shape\n",
    "        out_shape2 = out_shape * 2\n",
    "        out_shape3 = out_shape * 4\n",
    "        if len(in_shape) >= 4:\n",
    "            out_shape4 = out_shape * 8\n",
    "    scratch.layer1_rn = nn.Conv2d(in_shape[0], out_shape1, kernel_size=3, stride=1, padding=1, bias=False, groups=groups)\n",
    "    scratch.layer2_rn = nn.Conv2d(in_shape[1], out_shape2, kernel_size=3, stride=1, padding=1, bias=False, groups=groups)\n",
    "    scratch.layer3_rn = nn.Conv2d(in_shape[2], out_shape3, kernel_size=3, stride=1, padding=1, bias=False, groups=groups)\n",
    "    if len(in_shape) >= 4:\n",
    "        scratch.layer4_rn = nn.Conv2d(in_shape[3], out_shape4, kernel_size=3, stride=1, padding=1, bias=False, groups=groups)\n",
    "    return scratch\n",
    "\n",
    "# --- DPT Head 정의 ---\n",
    "class DPTHead(nn.Module):\n",
    "    def __init__(self, nclass, in_channels, features=256, use_bn=False, out_channels=[256, 512, 1024, 1024]):\n",
    "        super().__init__()\n",
    "        self.nclass = nclass\n",
    "\n",
    "        # 각 레벨별로 1x1 conv로 채널 맞추기\n",
    "        self.projects = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels, out_ch, kernel_size=1, stride=1, padding=0)\n",
    "            for out_ch in out_channels\n",
    "        ])\n",
    "\n",
    "        # 업샘플링 레이어: transposed conv 또는 identity 사용\n",
    "        self.resize_layers = nn.ModuleList([\n",
    "            nn.ConvTranspose2d(out_channels[0], out_channels[0], kernel_size=4, stride=4, padding=0),\n",
    "            nn.ConvTranspose2d(out_channels[1], out_channels[1], kernel_size=2, stride=2, padding=0),\n",
    "            nn.Identity(),\n",
    "            nn.Conv2d(out_channels[3], out_channels[3], kernel_size=3, stride=2, padding=1)\n",
    "        ])\n",
    "\n",
    "        # DPT의 scratch (refinement) 모듈\n",
    "        self.scratch = _make_scratch(out_channels, features, groups=1, expand=False)\n",
    "        self.scratch.refinenet1 = _make_fusion_block(features, use_bn)\n",
    "        self.scratch.refinenet2 = _make_fusion_block(features, use_bn)\n",
    "        self.scratch.refinenet3 = _make_fusion_block(features, use_bn)\n",
    "        self.scratch.refinenet4 = _make_fusion_block(features, use_bn)\n",
    "\n",
    "        # 출력 conv: 여기서는 depth map 예측 (nclass==1)\n",
    "        self.scratch.output_conv1 = nn.Conv2d(features, features // 2, kernel_size=3, stride=1, padding=1)\n",
    "        self.scratch.output_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(features // 2, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 1, kernel_size=1, stride=1, padding=0),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "    def forward(self, features, patch_h, patch_w):\n",
    "        outs = []\n",
    "        # features는 각 레벨에 대한 tensor 리스트, cls token 무시하고 첫번째만 사용\n",
    "        for i, x in enumerate(features):\n",
    "            # x의 첫번째 원소만 사용 (batch, seq, dim) → (batch, dim, patch_h, patch_w)\n",
    "            x = x[0]\n",
    "            x = x.permute(0, 2, 1).reshape(x.shape[0], x.shape[-1], patch_h, patch_w)\n",
    "            x = self.projects[i](x)\n",
    "            x = self.resize_layers[i](x)\n",
    "            outs.append(x)\n",
    "        layer1, layer2, layer3, layer4 = outs\n",
    "\n",
    "        # scratch 모듈로 각 레벨 정제\n",
    "        layer1_rn = self.scratch.layer1_rn(layer1)\n",
    "        layer2_rn = self.scratch.layer2_rn(layer2)\n",
    "        layer3_rn = self.scratch.layer3_rn(layer3)\n",
    "        layer4_rn = self.scratch.layer4_rn(layer4)\n",
    "\n",
    "        path4 = self.scratch.refinenet4(layer4_rn, size=layer3_rn.shape[2:])\n",
    "        path3 = self.scratch.refinenet3(path4, layer3_rn, size=layer2_rn.shape[2:])\n",
    "        path2 = self.scratch.refinenet2(path3, layer2_rn, size=layer1_rn.shape[2:])\n",
    "        path1 = self.scratch.refinenet1(path2, layer1_rn)\n",
    "\n",
    "        out = self.scratch.output_conv1(path1)\n",
    "        # 임시 patch size에 맞춰 보간 → 최종 depth 해상도에 맞게 업샘플\n",
    "        out = F.interpolate(out, (patch_h * 14, patch_w * 14), mode=\"bilinear\", align_corners=True)\n",
    "        out = self.scratch.output_conv2(out)\n",
    "        return out\n",
    "\n",
    "# --- DPT + DINOv2 Encoder ---\n",
    "class DepthModel(nn.Module):\n",
    "    def __init__(self, features=256, out_channels=[256, 512, 1024, 1024], use_bn=False, localhub=True):\n",
    "        \"\"\"\n",
    "        encoder는 DINOv2 pretrained 모델\n",
    "        DPT Head로 depth map 예측\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # encoder: dino v2 vitb14 고정\n",
    "        encoder = \"vitb\"\n",
    "        if localhub:\n",
    "            self.encoder = torch.hub.load(\n",
    "                'torchhub/facebookresearch_dinov2_main',\n",
    "                f'dinov2_{encoder}14',\n",
    "                source='local',\n",
    "                pretrained=False\n",
    "            )\n",
    "        else:\n",
    "            self.encoder = torch.hub.load(\n",
    "                'facebookresearch/dinov2',\n",
    "                f'dinov2_{encoder}14'\n",
    "            )\n",
    "\n",
    "        # pretrained encoder의 첫 블록의 qkv in_features를 사용\n",
    "        # 이거 실제 인풋이 아니라 채널만 맞춰주는 방식이야 !!\n",
    "        in_channels = self.encoder.blocks[0].attn.qkv.in_features\n",
    "\n",
    "        # DPT Head: depth map 예측 (nclass=1)\n",
    "        self.head = DPTHead(1, in_channels, features, use_bn, out_channels=out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h, w = x.shape[-2:]\n",
    "        # encoder로부터 중간 레벨 feature 4개 추출\n",
    "        features = self.encoder.get_intermediate_layers(x, 4, return_class_token=True)\n",
    "        patch_h, patch_w = h // 14, w // 14\n",
    "        depth = self.head(features, patch_h, patch_w)\n",
    "        # 최종 해상도에 맞게 보간\n",
    "        depth = F.interpolate(depth, size=(h, w), mode=\"bilinear\", align_corners=True)\n",
    "        depth = F.relu(depth)\n",
    "        return depth.squeeze(1)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T06:18:38.279689Z",
     "start_time": "2025-03-26T06:18:38.271757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def teacher_loss_function(pred,y):\n",
    "    \"\"\"\n",
    "    :param pred: Prediction per pixel. size : BxHxW\n",
    "    :param y: Ground truth. size : BxHxW\n",
    "    \"\"\"\n",
    "    B,H,W = pred.shape\n",
    "\n",
    "    #pred = torch.reshape(pred,(B,H*W))\n",
    "    #y = torch.reshape(y,(B,H*W))\n",
    "\n",
    "    pred = pred.view(B, H * W)\n",
    "    y = y.view(B, H * W)\n",
    "    loss_l= 0\n",
    "\n",
    "\n",
    "    def d_hat(d):\n",
    "        # 각 배치별 계산을 위해 dim 설정\n",
    "        # 여기서는 B x (HxW) 로 2차원이라고 가정\n",
    "        median, _ = torch.median(d, dim=-1) # 이러면 나오는 결과 : Bx1\n",
    "        # print(median)\n",
    "        t = median.unsqueeze(-1)\n",
    "        t = t.expand(-1,d.shape[-1])\n",
    "\n",
    "        #t = torch.matmul(median.unsqueeze(0),t)\n",
    "        s = torch.sum(torch.abs(d-t),dim=-1)/(d.shape[-1])\n",
    "        # s : Bx1 사이즈\n",
    "\n",
    "        s = s.unsqueeze(-1).expand(-1,d.shape[-1])\n",
    "\n",
    "        #print(\"d : \",d)\n",
    "        #print(\"t : \",t)\n",
    "        #print(\"s : \",s)\n",
    "        #print(\"분자 : \",torch.sum(d-t,dim=-1))\n",
    "\n",
    "        return (d-t)/s\n",
    "\n",
    "    def rho(pred,y):\n",
    "        return torch.abs(d_hat(pred) - d_hat(y))\n",
    "\n",
    "    loss_l = torch.sum(rho(pred,y),dim=-1) / pred.shape[-1]\n",
    "\n",
    "    return loss_l"
   ],
   "id": "ea69e3e4f320fbc4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T06:20:46.071248Z",
     "start_time": "2025-03-26T06:20:45.146937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == '__main__':\n",
    "    model = DepthModel(features=256, out_channels=[256, 512, 1024, 1024], use_bn=False, localhub=True)\n",
    "    print(model)"
   ],
   "id": "83f5000508514b0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DepthModel(\n",
      "  (encoder): DinoVisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
      "      (norm): Identity()\n",
      "    )\n",
      "    (blocks): ModuleList(\n",
      "      (0-11): 12 x NestedTensorBlock(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): MemEffAttention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (head): Identity()\n",
      "  )\n",
      "  (head): DPTHead(\n",
      "    (projects): ModuleList(\n",
      "      (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2-3): 2 x Conv2d(768, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (resize_layers): ModuleList(\n",
      "      (0): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (1): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (2): Identity()\n",
      "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (scratch): Module(\n",
      "      (layer1_rn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (layer2_rn): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (layer3_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (layer4_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (refinenet1): FeatureFusionBlock(\n",
      "        (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (rcu1): ResidualConvUnit(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (skip_add): FloatFunctional(\n",
      "            (activation_post_process): Identity()\n",
      "          )\n",
      "        )\n",
      "        (rcu2): ResidualConvUnit(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (skip_add): FloatFunctional(\n",
      "            (activation_post_process): Identity()\n",
      "          )\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (refinenet2): FeatureFusionBlock(\n",
      "        (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (rcu1): ResidualConvUnit(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (skip_add): FloatFunctional(\n",
      "            (activation_post_process): Identity()\n",
      "          )\n",
      "        )\n",
      "        (rcu2): ResidualConvUnit(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (skip_add): FloatFunctional(\n",
      "            (activation_post_process): Identity()\n",
      "          )\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (refinenet3): FeatureFusionBlock(\n",
      "        (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (rcu1): ResidualConvUnit(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (skip_add): FloatFunctional(\n",
      "            (activation_post_process): Identity()\n",
      "          )\n",
      "        )\n",
      "        (rcu2): ResidualConvUnit(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (skip_add): FloatFunctional(\n",
      "            (activation_post_process): Identity()\n",
      "          )\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (refinenet4): FeatureFusionBlock(\n",
      "        (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (rcu1): ResidualConvUnit(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (skip_add): FloatFunctional(\n",
      "            (activation_post_process): Identity()\n",
      "          )\n",
      "        )\n",
      "        (rcu2): ResidualConvUnit(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (skip_add): FloatFunctional(\n",
      "            (activation_post_process): Identity()\n",
      "          )\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (output_conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (output_conv2): Sequential(\n",
      "        (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d5959eb2e295e39"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
